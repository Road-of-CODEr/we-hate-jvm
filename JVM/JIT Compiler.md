# JIT Compiler    
      
**JVM의 핵심 기능**이라고 할 수 있는 `JIT Compiler`에 대해서 알아보고자 합니다.       
                                        
`JIT`의 의미는 `Just-In-Time`이라는 이름 그대로 `그 순간`을 의미합니다.    
한국말로, `적시생산시스템`이라 말할 수 있으며         
**`필요할 때, 필요한 만큼만 생산한다.`** 라는 철학을 가지고 있습니다.        
     
```  
단어의 어원 미국의 록히드 항공사가 슈퍼마켓 방식을 생산에 도입함으로써 상당한 효과를 봤다는        
홍보물을 본 도요타 자동차를 비롯한 일본 자동차 회사에서 자동차 생산에 적용한 데서 시작되었습니다.        
'필요한 것을, 필요한 때에, 필요한 만큼 만들어라'라는 모토를 가지고 있습니다.   
```        
         
**🤔 그렇다면 `JIT Compiler`는 어떤 것을 생산하는 것일까요?**            
바로, 런타임시에 CPU에서 직접 사용할 `바이너리 코드를`를 만드는 작업을 합니다.      
  
[컴파일과 인터프리트](#컴파일과-인터프리트)       
[핫스팟 컴파일](#핫스팟-컴파일)    
[JIT Compiler의 종류](#jit-compiler의-종류)   
[CoadCache 튜닝](#coadcache-튜닝)    
[컴파일 임계치](#컴파일-임계치)     
[컴파일 스레드](#컴파일-스레드)   
[인라이닝](#인라이닝)    
[탈출 분석](#탈출-분석)    
[이외에](#이외에)    
[참고](#참고)   
    

# 컴파일과 인터프리트           
CPU는 **어셈블리나 바이너리코드라고 불리는 특정 명령만을 실행시킬 수 있습니다.**            
즉, CPU가 실행하는 **프로그램들은 이러한 언어로 변환되어 실행되어야 한다**는 의미기도 합니다.      
   
* **컴파일형 언어 :** `C++`, `Forttarn`과 같은 언어는 한 번에 모든 코드를 읽고 해석         
* **인터프리터 언어 :** `PHP`, `Perl`, `python`과 같은 언어는 한 번에 한 줄의 코드만 읽고 해석  
                                           
`Java`는 흔히들 `컴파일 언어`라고 잘못 알고 있는 경우가 많은데 실은 **`인터프리터 언어`입니다.**                      
그렇기에 **한 번에 한 줄씩 수행하여 느리다는 인터프리터의 단점을 그대로 가지고 있습니다.**              
                                                                                   
`Java`는 여기서 절충안을 찾으려고 시도합니다.                 
바이트 코드를 `JIT Complier` 한 줄씩 읽으면서 `바이너리 코드`로 `변환`을 하는 방식을 채택했습니다.                    
여기까지는` Java Interpreter` 와 크게 다를게 없지만 **`JVM`의 `CodeCache`에 `Caching`해놓습니다.**                   
그렇기에, 같은 코드가 나오더라도 매번 바이너리 코드로 해석하는 작업을 하는 `Java Interpreter`와 달리,                
같은 코드가 나온다면 **다시 번역할 필요 없이 Code Cache에서 해당 바이너리 코드를 가져와 사용합니다.**                      
        
* **참고 - 자바가 인터프리터를 채택한 이유?:**                   
컴파일형 언어는 프로그램이 커질수록 컴파일 언어는 컴파일 시간이 길어진다는 문제가 있습니다.         
더불어 코드를 수정을 하게 되면, 다시 재 컴파일을 해야하기 때문에 컴파일 시간이 길면 안좋다는 문제가 있습니다.      
반면에, 인터프리터를 사용하면 해당 부분만 수정을 하면 된다는 이점이 있습니다.   
그렇기 때문에, 자바 뿐만 아니라 70%의 프로그래밍 언어가 이러한 이유때문에 인터프리터를 채택하고 있습니다.      


         
# 핫스팟 컴파일     
[파레토 법칙](https://ko.wikipedia.org/wiki/%ED%8C%8C%EB%A0%88%ED%86%A0_%EB%B2%95%EC%B9%99)처럼, 일반적인 프로그램은 전체 코드 중 일부만 자주 실행되며        
애플리케이션의 성능은 이 일부가 얼마나 빠르게 실행되는가에 의해 좌우됩니다.              
그리고 이러한 영역을 애플리케이션의 `핫스팟`이라고 합니다. (코드가 많이 실행될수록 핫해진다는 의미입니다.)       
          
`JIT Compiler`는 `Hot Spot Detection` 이라는 기술을 이용해   
일정시간 동안, 인터프리터가 코드를 해석하며 컴파일하는 과정에서           
충분할 정도로 자주 호출되는 메소드를 식별하고 핫스팟이라고 판단하여 컴파일을 진행합니다.(최적화도)       
그리고 이러한 핫스팟을 식별하고 컴파일하는 방식을 `핫스팟 컴파일`이라고 부릅니다.  
    
`JVM`은 코드를 실행하자 마자 바로, `컴파일`을 하지 않으며 이유가 두 가지가 있습니다.      
             
* **첫째 :**        
  한 번만 실행되는 코드를 컴파일하는 것은 헛수고이기 때문입니다.           
  컴파일해서 컴파일된 코드를 한 번만 실행하는 것보다(컴파일하는 시간 때문에)    
  자바 바이트코드를 인터프리트하는 편이 더 빠를 것입니다.      
  * 예를 들면, `System.out.println("Hello world!);` 한 줄만 있으면 인터프리터로 동작합니다.   
    
* **둘째 :**     
  최적화 때문입니다.     
  `JVM`이 특정 메소드나 루프를 **실행하는 시간이 길어질수록** 코드에 대해 얻어지는 정보가 많아지며    
  이를 통해 JVM이 코드를 컴파일할 때 이 내용을 바탕으로 효율적인 최적화를 적용할 수 있습니다.
    
최적화에 대해서 조금 더 설명해보고자 합니다.   
   
```java
public class RegisterTest{
    private int sum;
    
    public void calculateSum(int n){
        for(int i=0;i<=n;i++){
            sum += i;
        }
    }
	
}
```  
위 코드에서 `sum`은 메인 메모리에 저장되고 호출되어야 합니다.            
하지만, 메인 메모리에서 매번 값을 검색한다면 성능상 비효율적일 것입니다.     

그렇기에 `JIT Compiler`는 `sum`의 초기값을 **레지스터에 로드하고**    
레지스터내의 값을 이용해 `루프를 수행한 후` **메인 메모리에 결과 값을 저장할 것입니다.**

동기화에서는 스레드의 레지스터에 접근할 수 없기에 조금 달라지는데 이는 아래와 같습니다. 
       
```java
b = obj1.equals(obj2);  // 동기화 된 객체  
```      
위와 같은 코드가 있을 경우         
처음에는, 인터프리터가 `equals()`가 어떤 객체의 `equals()`인지 알기 위해서          
`Dynamic look up(Dynamin dispatch)`를 진행하면서 시간이 오래 걸릴 것입니다.       
                   
하지만 점차 시간이 지나면서         
`JVM`이 위와 같은 코드를 많이 실행했고 `obj1`의 자료형이 `String`이라고 가정을 한다면        
`JVM`은 `obj1.equals()`를 `String.equals()`로 만들어 최적화를 진행합니다.         
     
# JIT Compiler의 종류         
`JIT Compiler`는 `서버`와 `클라이언트` 두 가지 형태로 나뉘며,      
사용할 형태는 **프로그램이 수행되는 기간**과 **초기 스타트업 시간의 중요도**를 바탕으로 선택합니다.          
(현재 사용하는 컴파일러 종류는 java -version을 보면 확인 가능합니다.)      
                        
**Client Compiler**           
- `Start-up` 시간이 빠르며, 최적화를 위한 대기시간이 짧습니다        
- 하지만 최적화가 덜하기 때문에 `코드실행은 서버 컴파일러가 더 빠릅니다`      
              
**Server Compiler**            
- 클라이언트 컴파일러에 비해 `Start-up`이 느립니다.    
- 하지만, 컴파일 전에 많은 정보를 수집하여 **최적화에 중점을 두고 있습니다.**              
- 그리고, 서버 컴파일러는 절대로 모든 코드를 컴파일하지 않습니다.  (이유에 대해서는 찾아봐야겠습니다.)          

    
**Tiered Compile (-server -xx:+TieredCompilation )**     
- JDK 7 부터 도입되었으며, JDK 8 부터 기본 옵션으로 적용되었습니다.  
- **클라이언트 컴파일러로 스타트업 시간을 빠르게 하고, 많이 쓰이는 부분을 서버 컴파일러로 다시 컴파일하여 대체합니다.**    
- 이러한 `트레이드 오프`하는 과정에서 역최적화 후 서버 컴파일러로 재컴파일 됩니다.    
- 재컴파일 되는 시간은 성능에 영향을 줄 정도로 크지 않습니다.
- "-server -xx:+TieredCompilation" 옵션으로 명시합니다.       
    
**시간 비교**
- 스타트업 시간 : `-client` < `-xx:+TieredCompilation` < `-server`
- 코드실행 시간 : `- xx:+TieredCompilation` = `-server` < `-client`
- 상황에 따라 알맞은 컴파일러를 지정해서 사용하면 됩니다   
       
     
# CoadCache 튜닝     
앞서 말했듯이, `Coad Cache`는 재사용될 바이너리 코드가 저장되는 공간입니다.        
하지만, **가득 차게 되면 `JVM`은 더 이상 코드를 추가적으로 바이너리 코드로 컴파일할 수 없습니다.**     
이 말은 **애플리케이션의 많은 양의 부분이 인터프리터로 실행될 수 있다는 말입니다.**           
[실제 사례](https://helpx.adobe.com/kr/experience-manager/kb/aem-slow-java7.html)    

그렇기에 `Tiered Compile`나 `Client Compiler`를 사용하는           
**대형 프로그램**이라면 `Coad Cache`사이즈를 늘릴 필요가 있습니다.              
(Server Compiler는 몇 개의 소수 클래스만 컴파일하므로 Coad Cache를 채울 일은 그다지 없습니다.)       
           
**다양한 플랫폼에서의 Coad Cache 디폴트 값 목록**   

|JVM 타입|디폴트 코드 캐시 크기|
|--------|-------------------|
|32bit 클라이언트 자바 8|32MB|
|티어드 컴파일을 하는 32bit 자바 8|240MB|
|티어드 컴파일을 하는 64bit 자바 8|240MB|
|32bit 클라이언트 자바 7|32MB|
|32bit 서버 자바 7|32MB|
|64bit 서버 자바 7|48MB|
|티어드 컴파일을 하는 64bit 서버 자바 7|96MB|

                
단, 최적의 `Coad Cache`를 알아내기 위한 메커니즘은 따로 없습니다.         
그렇기에 `Coad Cache`의 최대 크기를 `-XX:ReservedCodeCacheSize=N` 플래그를 통해      
기존 설정된 값의 2배 또는 4배로 늘리고 모니터링을 하면서 찾는 방법밖에 없습니다.                  
   
모니터링하는 방법은 JDK가 설치되어있을 경우    
`cmd`나 `terminal`에서 `jconsole` 입력하면 실행가능합니다.      
이후, `Memory`탭으로 이동한 뒤에 `Memory Pool Code Cache` 상자를 클릭하면 됩니다.     
   
**궁금증 : 그러면 최대 코드 캐시로 실제 큰 값을 지정하여 공간이 부족하지 않게 하면 되지 않을까?🤔**   
`Coad Cache`의 크기는 `JVM`에서 사용 가능한 `물리적인 메모리`의 크기에 의존합니다.  
즉, 물리적인 메모리의 크기만 충분하다면 코드 캐시의 최대 크기를 마음껏 늘려도 됩니다.     
      
**명령어**  
   
```
-XX:ReservedCodeCacheSize=N
```
코드 캐시의 최대 크기를 지정합니다

```
-XX:InitialCodeCacheSize=N
```
초기 코드 캐시의 크기를 지정합니다
   
# 컴파일 임계치    
> method entry counter + back-edge loop counter     
     
JIT 컴파일러가 컴파일하는 조건은 얼마나 자주 코드가 실행됐는가입니다.     
일정한 횟수만큼 실행되고 나면 컴파일 임계치에 도달하고       
컴파일러는 컴파일하기에 충분한 정보가 쌓였다고 생각합니다.       
  
    
**컴파일의 기준이 되는 2개의 카운터**      
   
* JVM 내에 있는 메소드가 호출된 횟수
* 메소드가 루프를 빠져나오기까지 돈 횟수 
            
`JVM`은 두 카운터의 합계를 확인하고 메소드가 컴파일될 자격이 있는지 결정합니다.    
메서드가 컴파일 될 자격이 있다면 컴파일하기 위해 컴파일 큐에서 대기시키며       
큐에 있는 메소드들은 컴파일 스레드에 의해 컴파일됩니다.     
이러한 컴파일 방식을 `일반 컴파일`이라고 부릅니다.     
     
## OSR : On - Stack Replacement        
메서드의 길이가 너무 길거나, 루프가 정말 길 경우 **중간에 컴파일될 필요가 있습니다.**         
그래야 남은 반복을 중복하지 않고 빠르게 실행할 수 있기 때문입니다.             
따라서, `JVM`은 **루프의 실행을 그때그때 카운트**하고 임계치를 넘게 되면            
전체 메소드가 아닌 **루프만을 컴파일하여 컴파일된 버전을 바로 실행시킵니다.**             
이렇듯 스택상에서 **컴파일된 버전을 바로 실행시키는 것을 `OSR`이라고 합니다.**            
    
## 컴파일 임계치 변경하기    
컴파일 임계치를 변경하는 것은 권고하고 있습니다.       
* 에플리케이션이 `warm-up` 하는 데 필요한 시간을 절약할 수 있습니다.      
  * 어차피 10,000번 실행돼서 컴파일될 코드는 8,000번으로 줄여도 큰 차이 없기 때문입니다
* 컴파일 임계치를 낮추지 않으면 절대로 컴파일되지 않을 수 있는 메소드들이 있습니다.   
  * 컴파일 임계치에 가까이 있어,    
    아슬아슬하게 걸쳐서 컴파일되지 않는 메서드들을 컴파일해서 실행속도를 높힐 수 있습니다.
             
카운터값은 일정 시간(safepoint)동안 측정되는 상대적인 값입니다.   
그렇기 때문에, lukewarm method(긴 시간에 걸쳐서 많이 호출되는 메소드)들은 카운터값이 낮을 수 밖에 없습니다.       
따라서 컴파일 임계치를 낮춰서 컴파일해주는 것이 훨씬 더 좋습니다.         

**명령어**
```
-XX:CompileThreshold=N
```      
컴파일 임계치를 지정된 숫자만큼으로 변경합니다.     
       
클라이언트 컴파일러에서 기본값은 `1,500`     
서버 컴파일러의 기본값은 `10,000`입니다.    
       
ps)        
최근에 `스프링 네이티브`와 관련해서 이것저것 간략히만 알아봤는데           
JVM은 이런 `warm-up`이 느리다는 문제가 있어서 FaaS 환경에서 돌아가기 힘들다고 하네요       
그래서 `스프링 네이티브`는 `GraalVM`을 사용해서 이러한 문제를 조금이나마 해결했다고 하네요!         

# 컴파일 스레드
## 컴파일 스레드와 동기/비동기
컴파일 임계치에 다다라서 메소드가 컴파일 대상이 되면 컴파일 큐에 들어가 대기하게 됩니다.       
              
컴파일 큐는 한 개 이상의 **백그라운드 스레드(컴파일 스레드)**에 의해 처리되며      
`비동기 프로세스`로 대상 코드가 컴파일 중인 동안에도 계속해서 프로그램이 실행됩니다.     

```
참고로, 컴파일 큐는 FIFO 방식이 아니며 우선순위가 높은 메서드를 먼저 컴파일합니다.            
우선순위 선정 기준은 호출 카운터가 더 높은 메소드를 대상으로 더 높은 순위를 부여합니다.       
```   

이러한 프로세스 설정을 변경할 수 있는 `-XX:+BackgroundCompilation` 플래그도 있습니다.       
기본값은 `true`로 큐가 비동기 방식으로 처리되는 것을 말합니다.            
플래그를 `false`로 설정한다면 메소드가 컴파일되면 그걸 실행하길 원하는 코드는 실제로 컴파일될 때까지 기다리게 됩니다.   
   
**명령어**
```  
-XX:+BackgroundCompilation   
```     
컴파일 큐가 비동기 방식으로 처리되도록 설정합니다.    

```
-XX:-BackgroundCompilation
```
컴파일 큐가 동기 방식으로 처리되도록 설정합니다.    


## 컴파일 스레드의 개수  
컴파일러마다 사용하는 **백그라운드 스레드**의 개수는 다릅니다.  
  
* 클라이언트 컴파일러 : 1개
* 서버 컴파일러 : 2개
* 티어드 컴파일러 : JVM이 대상 플랫폼의 CPU 개수와 이중 로그에 관한 복잡한 방정식에 근거해 디폴트 스레드를 정한다.
    
**티어드 컴파일에서 C1과 C2 컴파일러 스레드 디폴트 값**   

|CPU 개수|Cilent Compiler 스레드 개수|Server Compiler 스레드 개수|
|-------|------------------------|-----------------------|
|1|1|1|
|2|1|1|
|4|1|2|
|8|1|2|
|16|2|6|
|32|3|7|
|64|4|8|
|128|4|10|   
        
이러한 티어드 컴파일에서의 `컴파일러 스레드 개수`는  `-X:CICompilerCount=N`플레그를 통해 조정이 가능합니다.         
**그렇다면 이 값을 언제, 어느 상황에 조정하는 게 나을까요? 🤔**     
     
제한된 CPU만을 사용할 수 있는 환경에서는    
더 적은 스레드가 그 자원을 두고 다투는 환경이 성능에 도움이 될 것입니다.           
물론 `warm-up`에서는 컴파일러 스레드가 더 많으면 스타트업 시간에는 우위가 있을 것이지만, 이득이 그렇게 크지 않습니다.   
준비 기간 이후에는 `많이 쓰이는 메소드들이 점점 컴파일 되므로` CPU를 두고 경쟁하는 일이 없어, CPU 보다 적게 스레드를 두는게 낫습니다.  

**명령어**
```
-X:CICompilerCount=N
```
컴파일을 수행할 컴파일러 스레드 개수를 정합니다.     

# 인라이닝     
인라이닝이란, JIT 컴파일러 수행하는 최적화 기법 중 하나로 `인라인 메소드`로 만드는 작업을 합니다.        
JVM은 기본적으로 `-XX:+Inline`가 설정되어 있어 메소드들을 자동으로 인라인화 할 수 있습니다.        
만약, 이를 해제하고 싶다면 `-XX:-Inline`(마이너스) 으로 재설정 하면 됩니다.   
   

```java
Point p = getPoint(); 
p.setX(p.getX() * 2)
```
인라인 메소드로 컴파일된 코드는 다음과 같습니다.

```java
Point p = getPoint(); 
p.x = p.x * 2;
```
이러한 인라이닝 기법은 디폴트로 사용되고 있으며         
실제로 반드시 사용해야 할 정도로 성능을 매우 효과적으로 향상시킵니다.
                
메소드의 인라인화를 결정하는 요소는 **얼마나 자주 호출되는지**와 **메소드의 크기** 입니다.   
JVM은 기본적으로 아래 2가지 상황에 대해서 인라인화를 진행합니다.     
     
`자주 호출되는 메소드` + `바이트 코드 크기가 325바이트보다 작음`이면 인라인화 합니다.     
`자주 호출되지 않는 메소드`+`바이트 코드가 35바이트보다 작음`이면 인라인화 됩니다.
      
**명령어**
```
-XX:+Inline
```
메서드 인라인화를 진행하는 것을 허락합니다.  

```
-XX:-Inline
```
메서드 인라인화를 진행하는 것을 거절합니다.      
    
```
-XX:MaxFreqInlineSize=N
```
자주 호출되는 경우의 바이트 코드는 `-XX:MaxFreqInlineSize` 플래그로 설정할 수 있습니다.   

```
--XX:MaxInlineSize=N
```
자주 호출되지 않는 경우의 바이트 코드는 `--XX:MaxInlineSize` 플래그로 설정할 수 있습니다.   
        
        
# 탈출 분석     
탈출 분석(Escape Analysis)은 **객체의 스코프를 분석해서 특정 스코프를 벗어날 수 있는지를 판단해 최적화를 적용하는 기법입니다.**   
   
* `동기화 락(synchronization lock)`을 제거하여 최적화를 진행합니다.      
* 객체가 로컬 스코프에 제한되어 있고 다른 영역으로 탈출(escape)할 가능성이 없다면,     
그 객체를 힙(heap) 영역에 생성하지 않고 **쓰레드의 로컬 스택에 생성**합니다.     
* 로컬 스택에 저장된 객체는 메소드가 종료될 때 곧바로 해제되며 힙 영역을 사용하지 않지만        
만약 객체를 힙에 저장한다면 기다렸다가 나중에 가비지 컬렉터로 해지합니다.       
       
JVM에는 기본적으로 탈출 분석 플래그(`-XX:+DoEscapeAnalysis`)가  설정되어 있으며   
만약, 이를 해제하고 싶다면 `-XX:-DoEscapeAnalysis.`(마이너스) 으로 재설정하면 됩니다.      
   
```java
public class Factorial {
    private BigInteger factorial;
    
    private int n;

    public Factorial(int n) {
        this.n = n;
    }
    
    public synchronized BigInteger getFactorial(){
        if(factorial == null) {
            factorial = BigInteger.valueOf(0);
        }
        return factorial;
    }
}
// 팩토리얼 값 100개를 저장
List<BigInteger> list = new ArrayList<>();

for (int i = 0; i < 100 ; i++) {
    Factorial factorial = new Factorial(i);     // 여기 
    list.add(factorial.getFactorial());
}
```

위의 코드를 보면 `Factorial 객체`의 스코프는 루프 내에서만 참조됩니다.       
그 외 다른 코드에서 팩토리얼 객체에 접근할 순 없습니다.       
이와 같은 경우에 JVM은 `탈출 분석`을 통해서 최적화를 진행합니다.    
    
* `getFactorial()` 메소드를 호출할 때 `동기화 락(synchronization lock)`을 걸 필요가 없습니다.
* 팩토리얼 객체에 있는 메모리 필드에 n을 저장할 필요가 없습니다.   
  어차피 루프가 끝나면 사라지므로 그냥 `레지스터에서 값`을 유지하면 됩니다.
* 팩토리얼 객체를 힙에 할당하지 않아도 됩니다.   
  어차피 `루프가 끝나면 사라지므로 그냥 로컬 스택에 사용`해도 됩니다.
          
# 이외에    
`역 최적화(문제가 생겼을 시 컴파일된 코드를 다시 역컴파일 시키는 것)`          
`티어드 컴파일 레벨(Tiered Compilation Level)`이란 내용도 있으나      
이 부분에 대해서는 설명이 불가능 할 것 같아서 정리하지 않았습니다.    
   
# 참고 
[oracle 공식문서(JVM option)](https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html)    
[자바 JIT 컴파일러](https://velog.io/@youngerjesus/%EC%9E%90%EB%B0%94-JIT-%EC%BB%B4%ED%8C%8C%EC%9D%BC%EB%9F%AC) 
[JIT : Just In Time Compiler 개념 & 튜닝](https://blog.naver.com/kbh3983/220985785358?proxyReferer=https%3A%2F%2Fwww.google.com%2F)   
[자바 성능 튜닝 스터디(1) JIT compiler](https://nopainnocode.tistory.com/15)    
[https://junshock5.tistory.com/111](https://junshock5.tistory.com/111)    
